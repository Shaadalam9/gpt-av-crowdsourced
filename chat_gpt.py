import os
import json
import base64
import pandas as pd
import common
from openai import OpenAI  # type: ignore
from langchain.memory import ConversationBufferMemory
from langchain.schema import messages_from_dict, messages_to_dict
from custom_logger import CustomLogger
from logmod import logs

logs(show_level='info', show_color=True)
logger = CustomLogger(__name__)  # use custom logger


class GPT_ImageAnalyser:
    """
    A class to analyze images using the GPT-4 Vision model.

    This class encodes the provided image, sends it to the GPT-4 Vision API along with a prompt,
    processes conversation history, updates a CSV file with the response, and manages conversation memory.
    """

    def __init__(self, image_path, prompt, use_history=True, max_memory_messages=6):
        """
        Initialize the GPT_ImageAnalyser with image, prompt, and conversation history settings.

        Args:
            image_path (str): The path to the image file to be analyzed.
            prompt (str): The prompt or instruction to be provided to the model.
            use_history (bool): Flag indicating whether to include conversation history.
            max_memory_messages (int): The maximum number of conversation history messages to store.
        """
        self.image_path = image_path
        self.prompt = prompt
        self.use_history = use_history
        self.max_memory_messages = max_memory_messages
        self.first_run = True  # Indicates whether this is the first analysis run.
        # The output CSV filename is set based on a random seed configuration.
        self.output_csv = os.path.join(common.get_configs("output"),
                                       f"output_{common.get_configs('random_seed')}.csv")
        self.model_name = "gpt-4o"
        # Initialize the OpenAI client for API calls.
        self.client = OpenAI(api_key=common.get_secrets("OPENAI_API_KEY"))  # type: ignore
        # File path to save conversation memory.
        self.memory_file = os.path.join(common.get_configs("output"), "chatgpt_memory.json")
        # Initialize conversation memory using LangChain.
        self.memory = ConversationBufferMemory(return_messages=True)
        # Load any existing conversation memory from file.
        self.load_memory()

    def load_memory(self):
        """
        Load conversation memory from a JSON file.

        If the memory file exists, it loads the messages and limits them to the last max_memory_messages.
        """
        try:
            with open(self.memory_file, "r") as f:
                messages = json.load(f)
                full_list = messages_from_dict(messages)
                # Limit the memory to the most recent messages.
                self.memory.chat_memory.messages = full_list[-self.max_memory_messages:]
        except FileNotFoundError:
            # If the memory file doesn't exist, proceed without loading.
            pass

    def save_memory(self):
        """
        Save the current conversation memory to a JSON file.
        """
        messages = messages_to_dict(self.memory.chat_memory.messages)
        with open(self.memory_file, "w") as f:
            json.dump(messages, f, indent=2)

    def analyse_image(self, seed=42):
        """
        Analyze the image using GPT-4 Vision and update the output CSV with the generated response.

        This method encodes the image to base64, builds the prompt (including conversation history if enabled),
        sends the request to the GPT-4 Vision model, saves the response to a CSV file,
        and updates the conversation memory.

        Args:
            seed (int): Seed value for reproducibility and to determine the output CSV filename.

        Returns:
            str: The content generated by the GPT-4 Vision model.
        """
        # Update the output CSV file based on the provided seed.
        self.output_csv = os.path.join(common.get_configs("output"), f"output_{seed}.csv")

        # Open and encode the image file to a base64 string.
        with open(self.image_path, "rb") as img_file:
            base64_image = base64.b64encode(img_file.read()).decode("utf-8")

        # Build the full prompt including conversation history if enabled and not the first run.
        if self.use_history and not self.first_run:
            formatted_history = ""
            # Iterate through stored messages and format them.
            for message in self.memory.chat_memory.messages:
                if message.__class__.__name__ == "HumanMessage":
                    formatted_history += f"History - Human: {message.content}\n"
                elif message.__class__.__name__ == "AIMessage":
                    formatted_history += f"History - AI: {message.content}\n"

            full_prompt = (
                f"{common.get_configs('base_prompt')}\n\n"
                f"{common.get_configs('history_intro')}\n"
                f"{formatted_history}\n"
                f"{common.get_configs('current_image_instruction')}"
            )
        else:
            full_prompt = self.prompt

        # Send the request to the GPT-4 Vision API via the OpenAI client.
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": full_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
            max_tokens=1000,
            temperature=common.get_configs("temperature")
        )

        # Extract the generated content from the API response.
        content = response.choices[0].message.content

        # Update conversation history if enabled.
        if self.use_history:
            self.memory.chat_memory.add_user_message(self.prompt)
            self.memory.chat_memory.add_ai_message(content)  # type: ignore
            # Keep only the most recent messages.
            self.memory.chat_memory.messages = self.memory.chat_memory.messages[-self.max_memory_messages:]
            self.save_memory()

        # Mark the first run as complete.
        self.first_run = False

        image_name = os.path.basename(self.image_path)
        try:
            # Try loading an existing CSV file with previous results.
            df = pd.read_csv(self.output_csv)
        except FileNotFoundError:
            # If not found, create a new DataFrame with an "image" column.
            df = pd.DataFrame(columns=["image"])

        # Ensure the column for the current model exists in the DataFrame.
        if self.model_name not in df.columns:
            df[self.model_name] = pd.NA

        # Update the DataFrame with the new response.
        if image_name in df["image"].values:
            df.loc[df["image"] == image_name, self.model_name] = content
        else:
            new_row = {"image": image_name, self.model_name: content}
            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

        # Save the updated DataFrame to CSV.
        df.to_csv(self.output_csv, index=False)
        logger.info(f"\nSaved GPT-4 Vision output for {image_name} to {self.output_csv}")
        return content


if __name__ == "__main__":
    # The main block is left empty for now.
    pass
